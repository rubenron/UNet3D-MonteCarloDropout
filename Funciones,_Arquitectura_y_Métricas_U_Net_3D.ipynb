{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtsEYjo1ppzX"
      },
      "source": [
        "El set de datos de entrenamiento fue sometido previamente a un ajuste de dimensiones para pasar de los originales 181x217x181 a 192x192x192."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**INSTALACIONES NECESARIAS**"
      ],
      "metadata": {
        "id": "Mu1cjM6qsw2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models # Modelos de segmentación preentrenados para tareas de visión por computadora\n",
        "!pip install nibabel # Carga y manipulación de imágenes médicas en formato NIfTI\n",
        "!pip install volumentations-3D # Aumentaciones de datos específicas para imágenes 3D"
      ],
      "metadata": {
        "id": "ZnZTt19h9GqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f16042-e5e8-44ac-e798-56bce1d8094c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl.metadata (938 bytes)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from segmentation-models)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting image-classifiers==1.0.0 (from segmentation-models)\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting efficientnet==1.0.0 (from segmentation-models)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.26.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.12.1)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (0.4)\n",
            "Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.12.2)\n",
            "Collecting volumentations-3D\n",
            "  Downloading volumentations_3D-1.0.4-py3-none-any.whl.metadata (481 bytes)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from volumentations-3D) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from volumentations-3D) (1.14.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from volumentations-3D) (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from volumentations-3D) (1.26.4)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->volumentations-3D) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->volumentations-3D) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->volumentations-3D) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->volumentations-3D) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->volumentations-3D) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->volumentations-3D) (0.4)\n",
            "Downloading volumentations_3D-1.0.4-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: volumentations-3D\n",
            "Successfully installed volumentations-3D-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FccM6SUMZp9"
      },
      "source": [
        "##**IMPORTAMOS LIBRERIAS NECESARIAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hodHB32DMdTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc78762-0ad2-487a-a4ab-2c19ffd21a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "# Importar librerías\n",
        "\n",
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "import segmentation_models as sm\n",
        "# CONFIGURAMOS KERAS COMO BACKEND DE segmentation_models\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()\n",
        "import matplotlib.pyplot as plt\n",
        "# Modelos, capas, backend, callbacks, regularizadores y pérdidas para la red neuronal.\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import (Input, Activation, BatchNormalization, SpatialDropout3D,\n",
        "                                     Conv3D, MaxPooling3D, UpSampling3D, Conv3DTranspose, concatenate)\n",
        "from tensorflow.data.experimental import AUTOTUNE\n",
        "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
        "from segmentation_models.metrics import IOUScore, FScore, Precision, Recall\n",
        "from tensorflow.keras.losses import Dice\n",
        "from sklearn.model_selection import KFold\n",
        "from volumentations import Compose, Flip, RandomRotate90\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccNULyWcz1Zi"
      },
      "source": [
        "#**DEFINIMOS LA FUNCIÓN DE PERDIDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCOgWUIYz17V"
      },
      "outputs": [],
      "source": [
        "# DEFINIMOS DICE LOSS\n",
        "dice_loss = Dice(reduction='sum_over_batch_size',name='dice') # El argumento reduction='sum_over_batch_size' especifica cómo se agrega la pérdida en todo el lote.\n",
        "# La función de pérdida Dice mide la superposición entre las máscaras de segmentación predichas y reales."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINIMOS PERDIDA FOCAL BINARIA PARA MANEJAR EL DESBALANCE DE CLASES (LESIONES Y FONDO)\n",
        "focal_loss = BinaryFocalCrossentropy(gamma=2.0)\n",
        "# Configura la pérdida de Entropía Cruzada Focal Binaria, que aborda el desequilibrio de clases asignando más peso a los píxeles difíciles de clasificar."
      ],
      "metadata": {
        "id": "0AGMTMQtucn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCIÓN DE PERDIDA COMBINADA\n",
        "def combined_loss(y_true, y_pred):\n",
        "    return dice_loss(y_true, y_pred) + focal_loss(y_true, y_pred)\n",
        "# La función combina la pérdida Dice y la pérdida Focal para crear una función de pérdida más robusta. Al sumar ambas pérdidas, se alienta al modelo a optimizar tanto la precisión\n",
        "# de la superposición (pérdida Dice) como el desequilibrio de clases (pérdida Focal)."
      ],
      "metadata": {
        "id": "AedIHl10uiRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DEFINIMOS METRICAS DE OPTIMIZACIÓN**"
      ],
      "metadata": {
        "id": "bDzEe9E8zUPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COEFICIENTE DE DICE\n",
        "dice_metric = FScore(beta=1, threshold=0.5, name='dice_metric')\n",
        "# DSC, también conocido como F1-score. El argumento threshold=0.5 especifica que las predicciones superiores a 0.5 se consideran positivas que tan bien coincide la máscara\n",
        "# predicha con el ground truth"
      ],
      "metadata": {
        "id": "SxhRLe_DzbVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INDICE DE JACCARD\n",
        "jaccard_metric = IOUScore(threshold=0.5, name='jaccard_metric') # Define el índice de Jaccard (Intersección sobre Unión, IoU) como métrica, también con un umbral de 0.5.\n",
        "# PRECISION, SENCIBILIDAD Y ESPECIFICIDAD\n",
        "precision_metric = Precision(threshold=0.5, name='precision_metric') # Indica la proporción de casos positivos predichos correctamente del total de casos positivos predichos.\n",
        "recall_metric = Recall(threshold=0.5, name='recall_metric') # Midie la proporción de casos positivos predichos correctamente del total de casos positivos reales."
      ],
      "metadata": {
        "id": "90BRvaV50N6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRmtzS-DMgRf"
      },
      "source": [
        "#**DEFINIMOS LA ARQUITECTURA U-Net 3D**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros del modelo\n",
        "bnorm_axis = -1 # Especifica el eje para la normalización por lotes. Un valor de -1 indica que la normalización por lotes debe aplicarse sobre el último eje (canales).\n",
        "nfilters = np.array([32, 48, 96, 192, 384]) # Experimentación\n",
        "drop_rate = 0.2 # Tasa de dropout para las capas SpatialDropout3D (para evitar el sobreajuste)\n",
        "input_shape = (192, 192, 192, 1)\n",
        "\n",
        "def unet_3d_version10(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # ============== Encoder ==============\n",
        "    # Encoder Block 0\n",
        "    e0 = Conv3D(filters=nfilters[0], kernel_size=(3,3,3), padding='same')(inputs)\n",
        "    e0 = BatchNormalization(axis=bnorm_axis)(e0)\n",
        "    e0 = Activation('relu')(e0)\n",
        "    e0 = Conv3D(filters=nfilters[0], kernel_size=(3,3,3), padding='same')(e0)\n",
        "    e0 = BatchNormalization(axis=bnorm_axis)(e0)\n",
        "    e0 = Activation('relu')(e0)\n",
        "\n",
        "    # Encoder Block 1\n",
        "    e1 = MaxPooling3D((2,2,2))(e0)\n",
        "    e1 = Conv3D(nfilters[1], (3,3,3), padding='same')(e1)\n",
        "    e1 = BatchNormalization(axis=bnorm_axis)(e1)\n",
        "    e1 = Activation('relu')(e1)\n",
        "    e1 = Conv3D(nfilters[1], (3,3,3), padding='same')(e1)\n",
        "    e1 = BatchNormalization(axis=bnorm_axis)(e1)\n",
        "    e1 = Activation('relu')(e1)\n",
        "\n",
        "    # Encoder Block 2\n",
        "    e2 = SpatialDropout3D(drop_rate)(e1, training=True)\n",
        "    e2 = MaxPooling3D((2,2,2))(e2)\n",
        "    e2 = Conv3D(nfilters[2], (3,3,3), padding='same')(e2)\n",
        "    e2 = BatchNormalization(axis=bnorm_axis)(e2)\n",
        "    e2 = Activation('relu')(e2)\n",
        "    e2 = Conv3D(nfilters[2], (3,3,3), padding='same')(e2)\n",
        "    e2 = BatchNormalization(axis=bnorm_axis)(e2)\n",
        "    e2 = Activation('relu')(e2)\n",
        "\n",
        "    # Encoder Block 3\n",
        "    e3 = SpatialDropout3D(drop_rate)(e2, training=True)\n",
        "    e3 = MaxPooling3D((2,2,2))(e3)\n",
        "    e3 = Conv3D(nfilters[3], (3,3,3), padding='same')(e3)\n",
        "    e3 = BatchNormalization(axis=bnorm_axis)(e3)\n",
        "    e3 = Activation('relu')(e3)\n",
        "    e3 = Conv3D(nfilters[3], (3,3,3), padding='same')(e3)\n",
        "    e3 = BatchNormalization(axis=bnorm_axis)(e3)\n",
        "    e3 = Activation('relu')(e3)\n",
        "\n",
        "    # ============== Bottleneck ==============\n",
        "    e4 = SpatialDropout3D(drop_rate)(e3, training=True)\n",
        "    e4 = MaxPooling3D((2,2,2))(e4)\n",
        "    e4 = Conv3D(nfilters[4], (3,3,3), padding='same')(e4)\n",
        "    e4 = BatchNormalization(axis=bnorm_axis)(e4)\n",
        "    e4 = Activation('relu')(e4)\n",
        "    e4 = Conv3D(nfilters[4], (3,3,3), padding='same')(e4)\n",
        "    e4 = BatchNormalization(axis=bnorm_axis)(e4)\n",
        "    e4 = Activation('relu')(e4)\n",
        "\n",
        "    # ============== Decoder ==============\n",
        "    # Decoder Block 3\n",
        "    d3 = SpatialDropout3D(drop_rate)(e4, training=True)\n",
        "    d3 = UpSampling3D((2,2,2))(d3)\n",
        "    d3 = concatenate([e3, d3])\n",
        "    d3 = Conv3DTranspose(nfilters[3], (3,3,3), padding='same')(d3)\n",
        "    d3 = BatchNormalization(axis=bnorm_axis)(d3)\n",
        "    d3 = Activation('relu')(d3)\n",
        "    d3 = Conv3DTranspose(nfilters[3], (3,3,3), padding='same')(d3)\n",
        "    d3 = BatchNormalization(axis=bnorm_axis)(d3)\n",
        "    d3 = Activation('relu')(d3)\n",
        "\n",
        "    # Decoder Block 2\n",
        "    d2 = SpatialDropout3D(drop_rate)(d3, training=True)\n",
        "    d2 = UpSampling3D((2,2,2))(d2)\n",
        "    d2 = concatenate([e2, d2])\n",
        "    d2 = Conv3DTranspose(nfilters[2], (3,3,3), padding='same')(d2)\n",
        "    d2 = BatchNormalization(axis=bnorm_axis)(d2)\n",
        "    d2 = Activation('relu')(d2)\n",
        "    d2 = Conv3DTranspose(nfilters[2], (3,3,3), padding='same')(d2)\n",
        "    d2 = BatchNormalization(axis=bnorm_axis)(d2)\n",
        "    d2 = Activation('relu')(d2)\n",
        "\n",
        "    # Decoder Block 1\n",
        "    d1 = UpSampling3D((2,2,2))(d2)\n",
        "    d1 = concatenate([e1, d1])\n",
        "    d1 = Conv3DTranspose(nfilters[1], (3,3,3), padding='same')(d1)\n",
        "    d1 = BatchNormalization(axis=bnorm_axis)(d1)\n",
        "    d1 = Activation('relu')(d1)\n",
        "    d1 = Conv3DTranspose(nfilters[1], (3,3,3), padding='same')(d1)\n",
        "    d1 = BatchNormalization(axis=bnorm_axis)(d1)\n",
        "    d1 = Activation('relu')(d1)\n",
        "\n",
        "    # Decoder Block 0\n",
        "    d0 = UpSampling3D((2,2,2))(d1)\n",
        "    d0 = concatenate([e0, d0])\n",
        "    d0 = Conv3DTranspose(nfilters[0], (3,3,3), padding='same')(d0)\n",
        "    d0 = BatchNormalization(axis=bnorm_axis)(d0)\n",
        "    d0 = Activation('relu')(d0)\n",
        "    d0 = Conv3DTranspose(nfilters[0], (3,3,3), padding='same')(d0)\n",
        "    d0 = BatchNormalization(axis=bnorm_axis)(d0)\n",
        "    d0 = Activation('relu')(d0)\n",
        "\n",
        "    # Capa de salida\n",
        "    outputs = Conv3D(1, (1,1,1), activation='sigmoid', padding='same')(d0)\n",
        "\n",
        "    # Compilación\n",
        "    # Usamos combined_loss (dice_loss + focal_loss) y las métricas definidas en la sección anterior\n",
        "    optimizer = tf.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5)\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=optimizer, loss=combined_loss, metrics=[dice_metric, jaccard_metric, precision_metric, recall_metric])\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "LBxt_3wppoxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7IdWC2rNkaH"
      },
      "source": [
        "#**FUNCIONES AUXILIARES**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################\n",
        "# Define un conjunto de aumentos aleatorios para aplicar a las imágenes y máscaras. Selecciona aleatoriamente volteos y rotaciones de 90 grados a lo largo de diferentes ejes.\n",
        "# Esta función se utiliza en la función apply_augmentation, que se llama durante el pipeline de entrenamiento.\n",
        "#####################################\n",
        "def get_random_augmentation():\n",
        "    augmentations = []\n",
        "    applied_augmentations = []\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        augmentations.append(Flip(0, p=1.0))\n",
        "        applied_augmentations.append('Flip en X')\n",
        "    if random.random() < 0.5:\n",
        "        augmentations.append(Flip(1, p=1.0))\n",
        "        applied_augmentations.append('Flip en Y')\n",
        "    if random.random() < 0.5:\n",
        "        augmentations.append(Flip(2, p=1.0))\n",
        "        applied_augmentations.append('Flip en Z')\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        augmentations.append(RandomRotate90((0, 1), p=1.0))\n",
        "        applied_augmentations.append('RandomRotate90 en XY')\n",
        "    if random.random() < 0.5:\n",
        "        augmentations.append(RandomRotate90((1, 2), p=1.0))\n",
        "        applied_augmentations.append('RandomRotate90 en YZ')\n",
        "    if random.random() < 0.5:\n",
        "        augmentations.append(RandomRotate90((0, 2), p=1.0))\n",
        "        applied_augmentations.append('RandomRotate90 en XZ')\n",
        "\n",
        "    if len(augmentations) == 0:\n",
        "        random_choice = random.choice([\n",
        "            (Flip(0, p=1.0), 'Flip en X'),\n",
        "            (Flip(1, p=1.0), 'Flip en Y'),\n",
        "            (Flip(2, p=1.0), 'Flip en Z'),\n",
        "            (RandomRotate90((0, 1), p=1.0), 'RandomRotate90 en XY'),\n",
        "            (RandomRotate90((1, 2), p=1.0), 'RandomRotate90 en YZ'),\n",
        "            (RandomRotate90((0, 2), p=1.0), 'RandomRotate90 en XZ')\n",
        "        ])\n",
        "        augmentations.append(random_choice[0])\n",
        "        applied_augmentations.append(random_choice[1])\n",
        "\n",
        "    return Compose(augmentations, p=1.0), applied_augmentations"
      ],
      "metadata": {
        "id": "ouLrgTJevJ0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################\n",
        "# Realiza dropout de Monte Carlo para estimar la incertidumbre de las predicciones del modelo. Ejecuta el modelo varias veces con dropout habilitado y\n",
        "# devuelve la media y la varianza de las predicciones.\n",
        "# Esta función se utiliza durante la fase de evaluación para analizar la incertidumbre de las predicciones del modelo.\n",
        "#####################################\n",
        "def predict_with_uncertainty(model, images, n_iter=1, batch_size=1):\n",
        "    num_images = images.shape[0] # Numero total de imagenes (numero de muestras)\n",
        "    all_preds = [] # Almacena las predicciones\n",
        "    for _ in range(n_iter): # bucle a ejecutar n veces\n",
        "        batch_preds = [] #Almacena las iteracciones para cada lote de imagenes\n",
        "        for i in range(0, num_images, batch_size): # Segundo Bucle, comienza en 0 y aumentan en batch_size hasta llegar al numero de imagenes\n",
        "            batch_images = images[i:i + batch_size] # Extrae un lote de imagenes usando los indices \"i\" del bucle anterior y lo guarda\n",
        "            pred = model(batch_images, training=True) # Realiza prediccion usando el modelo en el lote (training=True activa dropout en entrenamiento) y lo guarda\n",
        "            batch_preds.append(pred.numpy()) # Convierte pred a numpy y lo carga a la lista batch_preds\n",
        "        all_preds.append(np.concatenate(batch_preds, axis=0)) #Cuando se procesan todos los lotes de la iteracion, concatena las predicciones y las guarda\n",
        "    all_preds = np.array(all_preds) #Despues de todas las iteraciones all_preds se convierte a numpy (n_iter/#_imagenes/forma de salida del modelo[192,192,192,1])\n",
        "    mean_preds = np.mean(all_preds, axis=0) # Calcula la media de las predicciones en el eje 0 (eje de las iteraciones)-> PREDICCION PROMEDIO\n",
        "    var_preds = np.std(all_preds, axis=0) #np.var(all_preds, axis=0) # Calcula la varianza de las predicciones en el eje 0 (eje de las iteraciones)-> INCERTIDUMBRE PREDICCIONES\n",
        "    return mean_preds, var_preds, all_preds # RETORNA LAS PREDICCIONES PROMEDIO, INCERTIDUMBRE DE LAS PREDICCIONES Y TODAS LAS PREDICCIONES EN CADA ITERACION."
      ],
      "metadata": {
        "id": "datSBEJzSe-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0b0THqON4Im"
      },
      "outputs": [],
      "source": [
        "## OTRAS FUNCIONES AUXILIARES\n",
        "\n",
        "#####################################\n",
        "# Carga una imagen NIfTI desde la ruta de archivo especificada usando nib.load y devuelve los datos de la imagen y la matriz de transformación afín.\n",
        "# Esta función se utiliza en el pipeline.\n",
        "#####################################\n",
        "def load_nifti_image(filepath):\n",
        "    img = nib.load(filepath)\n",
        "    return img.get_fdata(), img.affine\n",
        "\n",
        "#####################################\n",
        "# Normaliza la imagen restando la media y dividiendo por la desviación estándar. También binariza la máscara estableciendo los valores mayores o iguales a 0.5 a 1\n",
        "# y los valores menores a 0.5 a 0.\n",
        "# Esta función se utiliza en el pipeline.\n",
        "#####################################\n",
        "def preprocess_image(image, mask):\n",
        "    # Normalizar la imagen (media cero y std uno)\n",
        "    image = (image - np.mean(image)) / (np.std(image) + 1e-7)\n",
        "    # Binarizar la máscara\n",
        "    mask = np.where(mask >= 0.5, 1, 0)\n",
        "    return image, mask\n",
        "\n",
        "#####################################\n",
        "# Aplica los aumentos seleccionados aleatoriamente a la imagen y máscara de entrada usando la librería volumentations.\n",
        "# Esta función se utiliza durante el pipeline de entrenamiento para aumentar la variabilidad de los datos de entrenamiento.\n",
        "#####################################\n",
        "def apply_augmentation(img, msk):\n",
        "    aug, applied_augmentations = get_random_augmentation()\n",
        "    augmented = aug(image=img, mask=msk)\n",
        "    return augmented['image'], augmented['mask']\n",
        "\n",
        "#####################################\n",
        "# Carga pares de imágenes y máscaras desde la ruta de carpeta especificada. Busca imágenes preprocesadas y máscaras correspondientes en los subdirectorios de la carpeta principal.\n",
        "# Esta función se utiliza para cargar los datos para entrenamiento, validación y prueba.\n",
        "#####################################\n",
        "\n",
        "def load_images_masks(folder_path):\n",
        "    \"\"\"\n",
        "    Devuelve lista con pares (imagen, mascara) Filtrar subdirectorios y ceros en create_dataset con la parte 'filtered_pairs'.\n",
        "    \"\"\"\n",
        "    image_mask_pairs = []\n",
        "    # Recorremos la carpeta principal\n",
        "    for subject in os.listdir(folder_path):\n",
        "        subject_folder      = os.path.join(folder_path, subject)\n",
        "        preprocessed_folder = os.path.join(subject_folder, 'preprocessed')\n",
        "        masks_folder        = os.path.join(subject_folder, 'masks')\n",
        "        # Revisar que existan\n",
        "        if not (os.path.isdir(preprocessed_folder) and os.path.isdir(masks_folder)):\n",
        "            print(\"[WARNING] -> Subcarpeta inválida:\", subject_folder)\n",
        "            continue\n",
        "        for file in os.listdir(preprocessed_folder):\n",
        "            if '_flair_pp_padded.nii' in file:\n",
        "                flair_image_path = os.path.join(preprocessed_folder, file)\n",
        "                mask_name        = file.replace('_flair_pp_padded.nii','_mask1_padded.nii')\n",
        "                mask_path        = os.path.join(masks_folder, mask_name)\n",
        "                if os.path.exists(mask_path) and os.path.isfile(flair_image_path):\n",
        "                    image_mask_pairs.append((flair_image_path, mask_path))\n",
        "                else:\n",
        "                    print(\"[WARNING] -> No existe la máscara o la imagen:\", flair_image_path, mask_path)\n",
        "\n",
        "    return image_mask_pairs\n",
        "\n",
        "\n",
        "###########################################\n",
        "# Esta es una función interna que realiza la carga y el aumento de datos reales. Toma las rutas de archivo de la imagen y la máscara como entrada, carga los datos usando\n",
        "# load_nifti_image, preprocesa los datos usando preprocess_image y aplica aumentos si el indicador augment está configurado como True.\n",
        "# Esta función se utiliza dentro de tf_load_preprocess.\n",
        "###########################################\n",
        "\n",
        "def _py_load_augment(f_str_tensor, m_str_tensor, augment):\n",
        "    \"\"\"Función interna que hace la carga (nib.load) + volumentations.\"\"\"\n",
        "    # Convertir EagerTensor -> str real\n",
        "    f_str = f_str_tensor.numpy().decode('utf-8')\n",
        "    m_str = m_str_tensor.numpy().decode('utf-8')\n",
        "    # 1) Carga nibabel\n",
        "    img_data, _ = load_nifti_image(f_str)\n",
        "    msk_data, _ = load_nifti_image(m_str)\n",
        "    # 2) Preprocesar\n",
        "    img_data, msk_data = preprocess_image(img_data, msk_data)\n",
        "    # 3) Augment si es True\n",
        "    if augment:\n",
        "        img_data, msk_data = apply_augmentation(img_data, msk_data)\n",
        "    # 4) Expandir dims\n",
        "    img_data = np.expand_dims(img_data, axis=-1)\n",
        "    msk_data = np.expand_dims(msk_data, axis=-1)\n",
        "\n",
        "    return img_data, msk_data\n",
        "\n",
        "###########################################\n",
        "# Esta función envuelve la función _py_load_augment para que sea compatible con la API tf.data de TensorFlow. Utiliza tf.py_function para ejecutar la función de Python\n",
        "# dentro del grafo de TensorFlow.\n",
        "# Esta función se utiliza para cargar y preprocesar los datos en paralelo.\n",
        "###########################################\n",
        "def tf_load_preprocess(f_p, m_p, augment):\n",
        "    \"\"\"Función principal que se llama desde create_dataset.\"\"\"\n",
        "    [img, msk] = tf.py_function(\n",
        "        func=_py_load_augment,\n",
        "        inp=[f_p, m_p, augment],\n",
        "        Tout=[tf.float32, tf.float32]\n",
        "    )\n",
        "    # Ajustamos shape fija\n",
        "    img.set_shape([192, 192, 192, 1])\n",
        "    msk.set_shape([192, 192, 192, 1])\n",
        "    return img, msk\n",
        "\n",
        "\n",
        "###########################################\n",
        "# Crea un conjunto de datos de TensorFlow a partir de una lista de pares de imagen-máscara. Mezcla los datos, aplica la función tf_load_preprocess para cargar y\n",
        "# preprocesar los datos, divide los datos en lotes y realiza una búsqueda previa de los datos para mejorar el rendimiento.\n",
        "# Esta función se utiliza para crear los conjuntos de datos de entrenamiento, validación y prueba.\n",
        "###########################################\n",
        "\n",
        "def create_dataset(image_mask_pairs, augment=False, batch_size=1):\n",
        "    \"\"\"Reemplazo de tu create_dataset usando lo anterior.\"\"\"\n",
        "    flair_paths = [pair[0] for pair in image_mask_pairs]\n",
        "    mask_paths  = [pair[1] for pair in image_mask_pairs]\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((flair_paths, mask_paths))\n",
        "    ds = ds.shuffle(buffer_size=len(flair_paths))\n",
        "\n",
        "    # Mapeamos con la closure que inyecta 'augment'\n",
        "    ds = ds.map(lambda f,m: tf_load_preprocess(f, m, augment),\n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "#####################################\n",
        "# FUNCIONES DE DEPURACIÓN\n",
        "# Verifica si la imagen está normalizada con una media cercana a 0 y una desviación estándar cercana a 1, y si la máscara está binarizada (contiene solo 0 y 1).\n",
        "# Esta función no se utiliza directamente en el pipeline de entrenamiento.\n",
        "#####################################\n",
        "\n",
        "def verificar_normalizacion(img, msk):\n",
        "    \"\"\"\n",
        "    Verifica si la imagen está normalizada con media cercana a 0 y std cercana a 1, y si la máscara está binarizada (contiene solo 0 y 1).\n",
        "    \"\"\"\n",
        "    # Asegurar que img y msk no tengan dimensión extra del canal si es [D,H,W,1]\n",
        "    if img.ndim == 4 and img.shape[-1] == 1:\n",
        "        img = img[...,0]\n",
        "    if msk.ndim == 4 and msk.shape[-1] == 1:\n",
        "        msk = msk[...,0]\n",
        "\n",
        "    media_imagen = np.mean(img)\n",
        "    std_imagen = np.std(img)\n",
        "    valores_unicos_mascara = np.unique(msk)\n",
        "    print(\"\\nVerificación de normalización:\")\n",
        "    print(f\"Media de la imagen: {media_imagen:.4f}, Desviación estándar de la imagen: {std_imagen:.4f}\")\n",
        "    if abs(media_imagen) < 1e-3 and abs(std_imagen - 1.0) < 1e-3:\n",
        "        print(\"La imagen parece estar correctamente normalizada (mean ~0, std ~1).\")\n",
        "    else:\n",
        "        print(\"La imagen NO está correctamente normalizada.\")\n",
        "    print(f\"Valores únicos en la máscara: {valores_unicos_mascara}\")\n",
        "    if np.array_equal(valores_unicos_mascara, [0, 1]):\n",
        "        print(\"La máscara es binaria (0 y 1).\")\n",
        "    else:\n",
        "        print(\"La máscara NO es binaria.\")\n",
        "\n",
        "###########################################\n",
        "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!   ############################    OJO      ############################   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# Crea un conjunto de datos de TensorFlow que incluye tanto las imágenes originales como las aumentadas. Concatena el conjunto de datos original con un conjunto de datos\n",
        "# aumentado y mezcla el conjunto combinado\n",
        "# Esta función no se utiliza en el pipeline de entrenamiento proporcionado.\n",
        "###########################################\n",
        "\n",
        "def create_dataset_both(image_mask_pairs, batch_size=1):\n",
        "    # Versión original (sin augment)\n",
        "    ds_orig = create_dataset(image_mask_pairs, augment=False, batch_size=batch_size)\n",
        "    # Versión aumentada (con augment)\n",
        "    ds_aug  = create_dataset(image_mask_pairs, augment=True, batch_size=batch_size)\n",
        "    # Concatenamos ambos\n",
        "    ds_both = ds_orig.concatenate(ds_aug)\n",
        "    # Re-barajamos para mezclar originales y aumentadas\n",
        "    ds_both = ds_both.shuffle(buffer_size=len(image_mask_pairs)*2) # opcional\n",
        "    return ds_both\n",
        "\n",
        "#####################################\n",
        "# Muestra una comparación entre una imagen original y su máscara versus una imagen aumentada y su máscara para un índice de corte dado.\n",
        "# Esta función no se utiliza directamente en el pipeline de entrenamiento.\n",
        "#####################################\n",
        "\n",
        "def mostrar_imagenes_y_mascaras(original_imagen, original_mascara, augmented_imagen, augmented_mascara, slice_index=100):\n",
        "    \"\"\"\n",
        "    Muestra comparaciones entre una imagen original y su máscara, vs. una imagen aumentada y su máscara.\n",
        "    \"\"\"\n",
        "    # Asegurar que las imágenes no tengan dimensión extra del canal si es [D,H,W,1]\n",
        "    def squeeze_channel(x):\n",
        "        if x.ndim == 4 and x.shape[-1] == 1:\n",
        "            return x[...,0]\n",
        "        return x\n",
        "    original_imagen = squeeze_channel(original_imagen)\n",
        "    original_mascara = squeeze_channel(original_mascara)\n",
        "    augmented_imagen = squeeze_channel(augmented_imagen)\n",
        "    augmented_mascara = squeeze_channel(augmented_mascara)\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    # Imagen original\n",
        "    plt.subplot(2, 2, 1)\n",
        "    #plt.imshow(original_imagen[:, :, slice_index], cmap='gray') #TRANSVERSAL\n",
        "    plt.imshow(original_imagen[:, slice_index, :], cmap='gray') # CORONAL\n",
        "    #plt.imshow(original_imagen[slice_index, :, :], cmap='gray') # SAGITAL\n",
        "    plt.title('Imagen Original')\n",
        "    plt.axis('off')\n",
        "    # Máscara original\n",
        "    plt.subplot(2, 2, 2)\n",
        "    #plt.imshow(original_mascara[:, :, slice_index], cmap='gray') #TRANSVERSAL\n",
        "    plt.imshow(original_mascara[:, slice_index, :], cmap='gray') # CORONAL\n",
        "    #plt.imshow(original_mascara[slice_index, :, :], cmap='gray') # SAGITAL\n",
        "    plt.title('Máscara Original')\n",
        "    plt.axis('off')\n",
        "    # Imagen aumentada\n",
        "    plt.subplot(2, 2, 3)\n",
        "    #plt.imshow(augmented_imagen[:, :, slice_index], cmap='gray') #TRANSVERSAL\n",
        "    plt.imshow(augmented_imagen[:, slice_index, :], cmap='gray') # CORONAL\n",
        "    #plt.imshow(augmented_imagen[slice_index, :, :], cmap='gray') # SAGITAL\n",
        "    plt.title('Imagen Aumentada')\n",
        "    plt.axis('off')\n",
        "    # Máscara aumentada\n",
        "    plt.subplot(2, 2, 4)\n",
        "    #plt.imshow(augmented_mascara[:, :, slice_index], cmap='gray') #TRANSVERSAL\n",
        "    plt.imshow(augmented_mascara[:, slice_index, :], cmap='gray') # CORONAL\n",
        "    #plt.imshow(augmented_mascara[slice_index, :, :], cmap='gray') # SAGITAL\n",
        "    plt.title('Máscara Aumentada')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "#####################################\n",
        "# FUNCIONES DURANTE ENTRENAMIENTO\n",
        "# Visualiza la imagen original, la máscara ground truth, la máscara predicha (media) y el mapa de incertidumbre (varianza) para un índice de corte dado.\n",
        "# Esta función se utiliza durante la fase de evaluación para visualizar las predicciones y la incertidumbre del modelo.\n",
        "#####################################\n",
        "\n",
        "def mostrar_prediccion_error(imagen, mascara_real, mascara_predicha_media, varianza_predicha, slice_index=100):\n",
        "    # Ajustar canales si es necesario\n",
        "    def _squeeze_channel(x):\n",
        "        if x.ndim == 4 and x.shape[-1] == 1:\n",
        "            return x[..., 0]\n",
        "        return x\n",
        "    # Convertir a [D,H,W] si hace falta\n",
        "    imagen = _squeeze_channel(imagen)\n",
        "    mascara_real = _squeeze_channel(mascara_real)\n",
        "    mascara_predicha_media = _squeeze_channel(mascara_predicha_media)\n",
        "    varianza_predicha = _squeeze_channel(varianza_predicha)\n",
        "\n",
        "    plt.figure(figsize=(16, 4))\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.imshow(imagen[:, :, slice_index], cmap='gray')\n",
        "    plt.title('Imagen')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.imshow(mascara_real[:, :, slice_index], cmap='gray')\n",
        "    plt.title('Máscara Real')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.imshow(mascara_predicha_media[:, :, slice_index], cmap='gray')\n",
        "    plt.title('Máscara Predicha (Media)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.imshow(varianza_predicha[:, :, slice_index], cmap='hot')\n",
        "    plt.title('Incertidumbre (Desviación Estandar)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wmk8hiJPbHP"
      },
      "source": [
        "#**INSTANCIAMOS VALIDACIÓN CRUZADA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGneBY1sPoL6"
      },
      "outputs": [],
      "source": [
        "# Validación cruzada de 6 pliegues\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "# Inicializa KFold con 6 FOLDS, mezcla los datos antes de dividirlos y establece un estado aleatorio para la reproducibilidad.\n",
        "# El modelo se entrenará y validará 6 veces, cada vez utilizando un fold diferente como conjunto de validación y los folds restantes como conjunto de entrenamiento."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}